import re
import textwrap
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup


BASE_URL = "https://malegislature.gov"


def fetch_committees_html() -> str:
    resp = requests.get(urljoin(BASE_URL, "/Committees"), timeout=20)
    resp.raise_for_status()
    return resp.text


def slugify_code(name: str, chamber_hint: str | None) -> str:
    """
    Turn 'House Committee on Bills in the Third Reading'
    into an internal code like 'HOUSE_BILLS_IN_THE_THIRD_READING'.

    This is opinionated â€“ tweak to fit your existing naming scheme.
    """
    n = name.strip()

    # Strip standard prefixes
    n = re.sub(r"^(House|Senate)\s+Committee\s+on\s+", "", n, flags=re.IGNORECASE)
    n = re.sub(r"^Joint\s+Committee\s+on\s+", "", n, flags=re.IGNORECASE)

    # Remove commas and "and" / ampersand normalization
    n = n.replace("&", "AND")
    n = re.sub(r"[^\w\s]", "", n)  # drop punctuation
    n = re.sub(r"\s+", "_", n.strip())

    if chamber_hint == "house":
        prefix = "HOUSE"
    elif chamber_hint == "senate":
        prefix = "SENATE"
    elif chamber_hint == "joint":
        prefix = "JOINT"
    else:
        prefix = "COMMITTEE"

    return f"{prefix}_{n.upper()}"


def infer_chamber_from_name(name: str) -> tuple[bool, str | None]:
    """
    Returns (is_joint, chamber_hint)

    - 'Joint Committee on ...' -> (True, 'joint')
    - 'House Committee on ...' -> (False, 'house')
    - 'Senate Committee on ...' -> (False, 'senate')
    """
    lower = name.lower()
    if lower.startswith("joint committee on"):
        return True, "joint"
    if lower.startswith("house committee on"):
        return False, "house"
    if lower.startswith("senate committee on"):
        return False, "senate"
    # Fallback: treat as joint with unknown chamber
    return False, None


def extract_external_id(href: str) -> str:
    """
    /Committees/Detail/H36  -> H36
    /Committees/Detail/J14/Committees  -> J14
    """
    parts = href.strip("/").split("/")
    # ["Committees", "Detail", "H36", ...]
    if len(parts) >= 3:
        return parts[2]
    return ""


def parse_committees(html: str) -> list[dict]:
    soup = BeautifulSoup(html, "html.parser")
    out: list[dict] = []

    for ul in soup.find_all("ul", class_="committeeList"):
        for li in ul.find_all("li", recursive=False):
            a = li.find("a", href=True)
            if not a:
                continue
            name = a.get_text(strip=True)
            href = a["href"]
            ext_id = extract_external_id(href)
            if not ext_id:
                continue

            is_joint, chamber_hint = infer_chamber_from_name(name)
            code = slugify_code(name, chamber_hint)

            out.append(
                {
                    "code": code,
                    "name": name,
                    "external_id": ext_id,
                    "is_joint": is_joint,
                    "chamber_hint": chamber_hint,
                }
            )

    return out


def print_committee_catalog_snippet(committees: list[dict]) -> None:
    """
    Print Python code you can paste into committee_catalog.py.
    """
    print("# Autogenerated from https://malegislature.gov/Committees")
    print("# Review codes before committing; adjust naming if needed.\n")
    print("_COMMITTEES = [")
    for c in committees:
        chamber_expr = (
            "Chamber.HOUSE"
            if c["chamber_hint"] == "house"
            else "Chamber.SENATE" if c["chamber_hint"] == "senate" else "None"
        )
        line = f"""Committee(
    code="{c['code']}",
    name="{c['name']}",
    chamber={chamber_expr},
    is_joint={str(c['is_joint']).lower()},
    external_ids=("{c['external_id']}",),
),"""
        # indent nicely
        indented = textwrap.indent(line, "    ")
        print(indented)
    print("]")
    print()
    print("COMMITTEES_BY_CODE = {c.code: c for c in _COMMITTEES}")
    print(
        "COMMITTEES_BY_EXTERNAL_ID = {ext: c for c in _COMMITTEES for ext in c.external_ids}"
    )


def main() -> None:
    """Prints the code for committee_catalog.py"""
    html = fetch_committees_html()
    committees = parse_committees(html)
    print_committee_catalog_snippet(committees)


if __name__ == "__main__":
    main()
